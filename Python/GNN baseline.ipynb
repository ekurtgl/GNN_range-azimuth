{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n",
      "10.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size # Optional[Tensor], Union[Tensor, SparseTensor], Optional[Tuple[int, int]], all about data type\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.nn import MessagePassing, GCNConv\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from torch_geometric.nn import global_mean_pool as gmeap, global_max_pool as gmp, global_add_pool as gap\n",
    "from torch_geometric.utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pickle, math\n",
    "import networkx as nx\n",
    "import numpy.matlib as matlib\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x7fdedb4b9320>\n",
      "3\n",
      "TITAN V\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 55, 256, 8)\n",
      "(4000, 20)\n",
      "(1000, 55, 256, 8)\n",
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "subj = 'RDAzimuth.pkl'\n",
    "filename = 'datasets/'+subj\n",
    "with open(filename, 'rb') as input:  # Overwrites any existing file.\n",
    "        x = pickle.load(input)\n",
    "x_tr, x_ts, y_tr, y_ts = [x[0], x[1], x[2], x[3]]\n",
    "print(x_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(x_ts.shape)\n",
    "print(y_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num vertices of the graph: 440\n",
      "Num edges of the graph: 1634\n"
     ]
    }
   ],
   "source": [
    "adj_ls = []\n",
    "nodes = []\n",
    "node = 0\n",
    "for i in range(x_tr.shape[1]):\n",
    "    for j in range(x_tr.shape[3]):\n",
    "        \n",
    "        init_ids = np.array([node-x_tr.shape[1], node+x_tr.shape[1], node-1, node+1])\n",
    "        mask1 = np.logical_and(init_ids >= 0, init_ids < x_tr.shape[1] * x_tr.shape[3])\n",
    "        mask2 = np.ones((4,))\n",
    "        \n",
    "        if node % x_tr.shape[1] == x_tr.shape[1]-1: # if right edge\n",
    "            mask2[3] = 0\n",
    "        if node % x_tr.shape[1] == 0: # if left edge\n",
    "            mask2[2] = 0\n",
    "        if node < x_tr.shape[1]: # if top edge\n",
    "            mask2[0] = 0\n",
    "        if node >= x_tr.shape[1]*x_tr.shape[3]: # if bottom edge\n",
    "            mask2[1] = 0\n",
    "            \n",
    "        mask = np.logical_and(mask1, mask2)\n",
    "        neighs = [init_ids[m] for m in range(len(init_ids)) if mask[m] == True]\n",
    "        adj_ls.append([(node,n) for n in neighs])\n",
    "        node += 1\n",
    "print('Num vertices of the graph:',len(adj_ls))\n",
    "adj_ls = [a for ad in adj_ls for a in ad]\n",
    "print('Num edges of the graph:',len(adj_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edges to mesh\n",
    "def edge2mesh(node,numcol):\n",
    "    div = node[0] // numcol\n",
    "    mod = node[0] % numcol\n",
    "    \n",
    "    div2 = node[1] // numcol\n",
    "    mod2 = node[1] % numcol\n",
    "    \n",
    "    return ((div+1, mod+1), (div2+1, mod2+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = [edge2mesh(a,x_tr.shape[1]) for a in sorted(adj_ls)]\n",
    "# for i in range(len(mesh)):\n",
    "#     print(mesh[i],'--',sorted(adj_ls[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394, 339) - ((8, 10), (7, 10))\n",
      "(394, 393) - ((8, 10), (8, 9))\n",
      "(394, 395) - ((8, 10), (8, 11))\n"
     ]
    }
   ],
   "source": [
    "for i,v in enumerate(sorted(adj_ls)):\n",
    "    if v[0] == 394:\n",
    "        print(v,'-',mesh[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1634/1634 [00:16<00:00, 99.77it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual =[m[0] for m in mesh]\n",
    "neigh =[m[1] for m in mesh]\n",
    "plt.figure(figsize=(12,3),dpi=100)\n",
    "# plt.hold\n",
    "for i in tqdm(range(len(mesh)),position=0):\n",
    "    plt.scatter(actual[i][1],actual[i][0],s=5,c='b')\n",
    "    plt.scatter(neigh[i][1],neigh[i][0],s=5,c='b')\n",
    "    if actual[i][1] == neigh[i][1]:\n",
    "        if actual[i][0] < neigh[i][0]:\n",
    "            plt.vlines(actual[i][1],actual[i][0]+0.2,neigh[i][0]-0.2,'r')\n",
    "        if actual[i][0] > neigh[i][0]:\n",
    "            plt.vlines(actual[i][1],neigh[i][0]+0.2,actual[i][0]-0.2,'r')\n",
    "    if actual[i][0] == neigh[i][0]:\n",
    "        if actual[i][1] < neigh[i][1]:\n",
    "            plt.hlines(actual[i][0],actual[i][1]+0.3,neigh[i][1]-0.3,'r')\n",
    "        if actual[i][1] > neigh[i][1]:\n",
    "            plt.hlines(actual[i][0],neigh[i][1]+0.3,actual[i][1]-0.3,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ready grid\n",
    "# x, y = np.meshgrid(np.linspace(0,x_tr.shape[1]-1, x_tr.shape[1]), np.linspace(0, x_tr.shape[3]-1, x_tr.shape[3]))\n",
    "\n",
    "# plt.figure(figsize=(12,3),dpi=100)\n",
    "# plt.scatter(x, y)\n",
    "\n",
    "# segs1 = np.stack((x,y), axis=2)\n",
    "# segs2 = segs1.transpose(1,0,2)\n",
    "# plt.gca().add_collection(LineCollection(segs1))\n",
    "# plt.gca().add_collection(LineCollection(segs2))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 55, 256, 8)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# x_data = np.log10(abs(np.concatenate([x_tr, x_ts],0))+1e-9 / np.max(abs(np.concatenate([x_tr, x_ts],0))+1e-9))\n",
    "x_data = abs(np.concatenate([x_tr, x_ts],0)) / np.max(abs(np.concatenate([x_tr, x_ts],0)))\n",
    "y_data = np.argmax(np.concatenate([y_tr, y_ts],0),-1)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 1.0 , Min: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Max:',np.max(x_data),', Min:',np.min(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start: 0 , Train end: 3999\n",
      "Test start: 4000 , Test end: 4999\n"
     ]
    }
   ],
   "source": [
    "train_mask = list(range(len(x_tr)))\n",
    "test_mask = list(range(len(x_tr),len(x_tr)+len(x_ts)))\n",
    "print('Train start:',min(train_mask),', Train end:',max(train_mask))\n",
    "print('Test start:',min(test_mask),', Test end:',max(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(i):\n",
    "#     data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "#     data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "#     data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "#     data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape \n",
    "#             [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "#     data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "\n",
    "    data = Data(x=torch.tensor(x_data[i].reshape(-1,x_data.shape[1]*x_data.shape[3]).T, dtype=torch.float), y=torch.tensor(y_data[i], dtype=torch.long),\n",
    "                edge_index=torch.tensor(adj_ls, dtype = torch.long).T)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor defines two GCNConv layers which get called in the forward pass of our network.\n",
    "Note that the non-linearity is not integrated in the conv calls and hence needs to be applied afterwards (something which is consistent accross all operators in PyG). Here, we chose to use ReLU as our intermediate non-linearity and finally output a softmax distribution over the number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model to make prediction for each node\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = GCNConv(x_data.shape[2], 16)\n",
    "#         self.conv2 = GCNConv(16, len(np.unique(y_data)))\n",
    "#         self.pool1 = torch.nn.Linear()\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "\n",
    "#         return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to make prediction for the whole graph\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(x_data.shape[2], 64, add_self_loops=True, improved=True)\n",
    "        self.conv2 = GCNConv(64, 64, add_self_loops=True, improved=True)\n",
    "#         self.pool1 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(64,1)))\n",
    "#         self.pool1 = gnn.global_add_pool(self.x, self.batch)\n",
    "#         self.lin1 = torch.nn.Linear(len(np.unique(y_data)),1)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "#         x = self.pool1(x, batch)\n",
    "        x = gmp(x, batch)\n",
    "        return F.softmax(x, dim=-1)#.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, indices=list(range(len(x_data))), transform=None):\n",
    "        self.transform = transform\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return process_data(self.indices[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(prog_bar = True):\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    max_test_acc = 0\n",
    "    train_loader = DataLoader(MyDataset(indices=train_mask), batch_size=batch_size)\n",
    "    test_loader = DataLoader(MyDataset(indices=test_mask), batch_size=batch_size)\n",
    "    tr_acc_ls = []\n",
    "    ts_acc_ls = []\n",
    "    pred_ls = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        if prog_bar:\n",
    "            pbar = tqdm(train_loader,position=0)\n",
    "        else:\n",
    "            pbar = train_loader\n",
    "        tr_acc = []\n",
    "        ts_acc = []\n",
    "        # train\n",
    "        for data in pbar:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "#             print('out',output.shape)\n",
    "#             print('data.y',data.y.shape)\n",
    "            loss = F.cross_entropy(output, data.y) #.reshape(batch_size,y_data.shape[-1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_acc.append((data.y.cpu().detach().numpy() == np.argmax(output.cpu().detach().numpy(),-1)).sum() / batch_size)\n",
    "            if prog_bar:\n",
    "                pbar.set_description('Train Acc: '+str(tr_acc[-1]))\n",
    "            train_loss += loss.cpu().detach().numpy()/len(train_loader)\n",
    "        tr_acc_ls.append(tr_acc)      \n",
    "        \n",
    "        # test\n",
    "        pred = []\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, data.y)\n",
    "            test_loss += loss.cpu().detach().numpy()/len(test_loader)\n",
    "            pred.append(output.cpu().detach().numpy())\n",
    "            ts_acc.append((data.y.cpu().detach().numpy() == np.argmax(output.cpu().detach().numpy(),-1)).sum() / batch_size)\n",
    "        if ts_acc[-1] < max_test_acc:\n",
    "            print('Max acc changed from '+str(max_test_acc)+' to '+str(ts_acc[-1]))\n",
    "            max_test_acc = ts_acc[-1]\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "        pred_ls.append(pred)\n",
    "        ts_acc_ls.append(ts_acc) \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        if epoch > 10 and np.mean(ts_acc_ls[-7:]) < max_test_acc + 1e9: # early stop\n",
    "            break\n",
    "        lr_scheduler.step(test_loss)\n",
    "        print('Epoch: ', str(epoch+1)+'/'+str(epochs),'| Training acc: ', np.mean(tr_acc_ls[-1]),\\\n",
    "              '| Testing acc: ', np.mean(ts_acc_ls[-1]))\n",
    "        \n",
    "        if not prog_bar:\n",
    "            plt.plot(train_losses, label=\"Train Loss\")\n",
    "            plt.plot(test_losses, label=\"Validation Loss\")\n",
    "            plt.xlabel(\"# Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.show()\n",
    "    return train_losses, test_losses, tr_acc_ls, ts_acc_ls, pred_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.060546875: 100%|██████████| 4/4 [00:51<00:00, 12.84s/it] \n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/50 | Training acc:  0.051513671875 | Testing acc:  0.06640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0576171875: 100%|██████████| 4/4 [00:52<00:00, 13.14s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2/50 | Training acc:  0.05908203125 | Testing acc:  0.0654296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.076171875: 100%|██████████| 4/4 [00:51<00:00, 12.80s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3/50 | Training acc:  0.0693359375 | Testing acc:  0.0869140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:48<00:00, 12.06s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:49<00:00, 12.43s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:49<00:00, 12.32s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:47<00:00, 11.93s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:51<00:00, 12.82s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:50<00:00, 12.52s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:48<00:00, 12.04s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:48<00:00, 12.13s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11/50 | Training acc:  0.073974609375 | Testing acc:  0.087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.0771484375: 100%|██████████| 4/4 [00:48<00:00, 12.02s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "batch_size = 2**10\n",
    "epochs = 50\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=3, factor=0.5)\n",
    "\n",
    "model_name = 'models/GNN_baseline' + subj[:-4] + '.pth'\n",
    "train_losses, test_losses, tr_acc_ls, ts_acc_ls, pred_ls = train(prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart notebook if \"RuntimeError: CUDA error: device-side assert triggered CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
    "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ls[-1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ls[-2][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
