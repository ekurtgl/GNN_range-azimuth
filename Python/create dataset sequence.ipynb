{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: datasets/RDAzimuth_seq.pkl\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob, scipy, pickle, itertools, re\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io as sio\n",
    "import mat73\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "subj = 'RDAzimuth'\n",
    "filename = 'datasets/'+subj+'_seq.pkl' # _resized\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Files: 182\n"
     ]
    }
   ],
   "source": [
    "mdpath = '../../'+subj+'/*.mat'\n",
    "addr = glob.glob(mdpath)\n",
    "# addr = addr[:5000]\n",
    "print('Num. Files: '+str(len(addr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../RDAzimuth\\\\11010000_1603570411_Raw_0_1_001.mat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_id: 18\n",
      "01\n",
      "frame_id: 43\n",
      "unique: 11010000_1603570411_Raw_0_1\n"
     ]
    }
   ],
   "source": [
    "slash_id = addr[0].rfind(\"\\\\\")\n",
    "class_id = slash_id+3\n",
    "frame_id = addr[0].rfind(\"_\")\n",
    "print('class_id:',class_id)\n",
    "print(addr[0][class_id:class_id+2])\n",
    "print('frame_id:',frame_id)\n",
    "print('unique:',addr[0][slash_id+1:frame_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. uniques: 3\n"
     ]
    }
   ],
   "source": [
    "fname_ls = np.unique([a[slash_id+1:frame_id] for a in addr])\n",
    "print('Num. uniques:',len(fname_ls))\n",
    "p = np.random.permutation(len(fname_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected num. samples:  3\n"
     ]
    }
   ],
   "source": [
    "num_sample = 100\n",
    "fname_ls = fname_ls[p]\n",
    "fname_ls = fname_ls[:num_sample]\n",
    "print('Selected num. samples: ', len(fname_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many frames in a uniq id\n",
    "cnt = 0\n",
    "uniq_id = -1\n",
    "for i in addr:\n",
    "    if fname_ls[uniq_id] in i:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 256, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one sample\n",
    "data = mat73.loadmat(addr[0])['crop_frame']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "labels = []\n",
    "for i,v in tqdm(enumerate(fname_ls),position=0):\n",
    "    \n",
    "    indices = []\n",
    "    for k,a in enumerate(addr):\n",
    "        if v in a:\n",
    "            indices.append(k)\n",
    "    subarray = np.zeros((len(indices),data.shape[0],data.shape[1],data.shape[2]),dtype=complex)\n",
    "    for j in range(len(indices)):\n",
    "        subarray[j] = mat73.loadmat(addr[indices[j]])['crop_frame']\n",
    "    labels.append(int(addr[indices[j]][class_id:class_id+2])-1)\n",
    "    dataset.append(subarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset, dtype ='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 3})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Classes: ', np.unique(sorted(labels)))\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 1)\n",
      "(1,)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_ts, y_tr, y_ts = train_test_split(dataset,np.array(to_categorical(labels)),test_size=0.2,random_state=1)\n",
    "print(x_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(x_ts.shape)\n",
    "print(y_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/RDAzimuth_seq_100.pkl created.\n"
     ]
    }
   ],
   "source": [
    "data = [x_tr,x_ts,y_tr,y_ts]\n",
    "filename = filename.replace('.pkl','_'+str(num_sample)+'.pkl')\n",
    "with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(data, output, pickle.HIGHEST_PROTOCOL)\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 55, 256, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
